\begin{thebibliography}{10}

\bibitem{battaglia_interaction_2016}
P.~W. Battaglia, R.~Pascanu, M.~Lai, D.~Rezende, and K.~Kavukcuoglu.
\newblock Interaction {Networks} for {Learning} about {Objects}, {Relations}
  and {Physics}.
\newblock {\em arXiv:1612.00222 [cs]}, Dec. 2016.
\newblock arXiv: 1612.00222.

\bibitem{chen_neural_2018}
R.~T.~Q. Chen, Y.~Rubanova, J.~Bettencourt, and D.~K. Duvenaud.
\newblock Neural {Ordinary} {Differential} {Equations}.
\newblock In S.~Bengio, H.~Wallach, H.~Larochelle, K.~Grauman, N.~Cesa-Bianchi,
  and R.~Garnett, editors, {\em Advances in {Neural} {Information} {Processing}
  {Systems} 31}, pages 6571--6583. Curran Associates, Inc., 2018.

\bibitem{cranmer_lagrangian_2020}
M.~Cranmer, S.~Greydanus, S.~Hoyer, P.~Battaglia, D.~Spergel, and S.~Ho.
\newblock Lagrangian {Neural} {Networks}.
\newblock {\em arXiv:2003.04630 [physics, stat]}, Mar. 2020.
\newblock arXiv: 2003.04630.

\bibitem{devlin_bert_2019}
J.~Devlin, M.-W. Chang, K.~Lee, and K.~Toutanova.
\newblock {BERT}: {Pre}-training of {Deep} {Bidirectional} {Transformers} for
  {Language} {Understanding}.
\newblock {\em arXiv:1810.04805 [cs]}, May 2019.
\newblock arXiv: 1810.04805.

\bibitem{finzi_generalizing_2020}
M.~Finzi, S.~Stanton, P.~Izmailov, and A.~G. Wilson.
\newblock Generalizing {Convolutional} {Neural} {Networks} for {Equivariance}
  to {Lie} {Groups} on {Arbitrary} {Continuous} {Data}.
\newblock {\em arXiv:2002.12880 [cs, stat]}, May 2020.
\newblock arXiv: 2002.12880.

\bibitem{greydanus_hamiltonian_2019}
S.~Greydanus, M.~Dzamba, and J.~Yosinski.
\newblock Hamiltonian {Neural} {Networks}.
\newblock In H.~Wallach, H.~Larochelle, A.~Beygelzimer, F.~d. Alché-Buc,
  E.~Fox, and R.~Garnett, editors, {\em Advances in {Neural} {Information}
  {Processing} {Systems} 32}, pages 15379--15389. Curran Associates, Inc.,
  2019.

\bibitem{he_mask_2018}
K.~He, G.~Gkioxari, P.~Dollár, and R.~Girshick.
\newblock Mask {R}-{CNN}.
\newblock {\em arXiv:1703.06870 [cs]}, Jan. 2018.
\newblock arXiv: 1703.06870.

\bibitem{hornik_multilayer_1989}
K.~Hornik, M.~Stinchcombe, and H.~White.
\newblock Multilayer feedforward networks are universal approximators.
\newblock {\em Neural Networks}, 2(5):359--366, Jan. 1989.

\bibitem{lutter_deep_2019}
M.~Lutter, C.~Ritter, and J.~Peters.
\newblock Deep {Lagrangian} {Networks}: {Using} {Physics} as {Model} {Prior}
  for {Deep} {Learning}.
\newblock {\em arXiv:1907.04490 [cs, eess, stat]}, July 2019.
\newblock arXiv: 1907.04490.

\bibitem{pukrittayakamee_simultaneous_2009}
A.~Pukrittayakamee, M.~Malshe, M.~Hagan, L.~M. Raff, R.~Narulkar,
  S.~Bukkapatnum, and R.~Komanduri.
\newblock Simultaneous fitting of a potential-energy surface and its
  corresponding force fields using feedforward neural networks.
\newblock {\em The Journal of Chemical Physics}, 130(13):134101, Apr. 2009.

\bibitem{raissi_physics_2017}
M.~Raissi, P.~Perdikaris, and G.~E. Karniadakis.
\newblock Physics {Informed} {Deep} {Learning} ({Part} {I}): {Data}-driven
  {Solutions} of {Nonlinear} {Partial} {Differential} {Equations}.
\newblock {\em arXiv:1711.10561 [cs, math, stat]}, Nov. 2017.
\newblock arXiv: 1711.10561.

\bibitem{raissi_physics-informed_2019}
M.~Raissi, P.~Perdikaris, and G.~E. Karniadakis.
\newblock Physics-informed neural networks: {A} deep learning framework for
  solving forward and inverse problems involving nonlinear partial differential
  equations.
\newblock {\em Journal of Computational Physics}, 378:686--707, Feb. 2019.

\bibitem{sanchez-gonzalez_hamiltonian_2019}
A.~Sanchez-Gonzalez, V.~Bapst, K.~Cranmer, and P.~Battaglia.
\newblock Hamiltonian {Graph} {Networks} with {ODE} {Integrators}.
\newblock {\em arXiv:1909.12790 [physics]}, Sept. 2019.
\newblock arXiv: 1909.12790.

\bibitem{sanchez-gonzalez_learning_2020}
A.~Sanchez-Gonzalez, J.~Godwin, T.~Pfaff, R.~Ying, J.~Leskovec, and P.~W.
  Battaglia.
\newblock Learning to {Simulate} {Complex} {Physics} with {Graph} {Networks}.
\newblock {\em arXiv:2002.09405 [physics, stat]}, Feb. 2020.
\newblock arXiv: 2002.09405.

\bibitem{sanchez-gonzalez_graph_2018}
A.~Sanchez-Gonzalez, N.~Heess, J.~T. Springenberg, J.~Merel, M.~Riedmiller,
  R.~Hadsell, and P.~Battaglia.
\newblock Graph networks as learnable physics engines for inference and
  control.
\newblock {\em arXiv:1806.01242 [cs, stat]}, June 2018.
\newblock arXiv: 1806.01242.

\bibitem{toussaint_differentiable_2018}
M.~Toussaint, K.~Allen, K.~Smith, and J.~Tenenbaum.
\newblock Differentiable {Physics} and {Stable} {Modes} for {Tool}-{Use} and
  {Manipulation} {Planning}.
\newblock In {\em Robotics: {Science} and {Systems} {XIV}}. Robotics: Science
  and Systems Foundation, June 2018.

\bibitem{yao_tensormol-01_2018}
K.~Yao, J.~E. Herr, D.~Toth, R.~Mckintyre, and J.~Parkhill.
\newblock The {TensorMol}-0.1 model chemistry: a neural network augmented with
  long-range physics.
\newblock {\em Chemical Science}, 9(8):2261--2269, 2018.

\bibitem{zhong_dissipative_2020}
Y.~D. Zhong, B.~Dey, and A.~Chakraborty.
\newblock Dissipative {SymODEN}: {Encoding} {Hamiltonian} {Dynamics} with
  {Dissipation} and {Control} into {Deep} {Learning}.
\newblock {\em arXiv:2002.08860 [cs, eess, stat]}, Apr. 2020.
\newblock arXiv: 2002.08860.

\bibitem{zhu_deep_2020}
A.~Zhu, P.~Jin, and Y.~Tang.
\newblock Deep {Hamiltonian} networks based on symplectic integrators.
\newblock {\em arXiv:2004.13830 [cs, math]}, Apr. 2020.
\newblock arXiv: 2004.13830.

\end{thebibliography}
